{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vGQCEjo0WhQ1"
      ],
      "authorship_tag": "ABX9TyPeKMFxw7+S4apdwBVCYFpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lukas-Pupelis/Kursinis/blob/main/Kursinis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdsScBENtXql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ef3afa70-bfca-44ca-ce3c-d0265ef99f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (0.20.1+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pretrainedmodels) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->pretrainedmodels) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pretrainedmodels) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pretrainedmodels) (3.0.2)\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
        "from scipy.stats import ttest_rel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import seaborn as sns\n",
        "!pip install pretrainedmodels\n",
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive_dir = drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp5XYW98ubsH",
        "outputId": "1bea33eb-273e-418b-b305-ce54a331652f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/mp'\n",
        "weight_dir = '/content/drive/My Drive/clam_weights/pre-trained_weights'\n",
        "model_dir = '/content/drive/My Drive/MP-Net/src/segmentation_models/segmentation_models_pytorch'\n",
        "root_dir = \"/content/drive/My Drive/MP-Net/src/segmentation_models\"\n",
        "images_dir = os.path.join(data_dir, 'images')\n",
        "masks_dir = os.path.join(data_dir, 'masks')\n",
        "unet_dir = os.path.join(model_dir, 'unet')\n",
        "resized_images_dir = os.path.join(data_dir, 'resized_images')\n",
        "resized_masks_dir = os.path.join(data_dir, 'resized_masks')\n",
        "inverted_resized_masks_dir = os.path.join(data_dir, 'inverted_resized_masks')"
      ],
      "metadata": {
        "id": "V-mE15StuCjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "yTSRfWJZliMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from importlib import import_module\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  if root_dir not in sys.path:\n",
        "      sys.path.append(root_dir)\n",
        "\n",
        "  # 3. Check existence\n",
        "  if not os.path.isdir(unet_dir):\n",
        "      print(f\"Error: The 'unet' directory was not found at '{unet_dir}'.\")\n",
        "      sys.exit(1)\n",
        "\n",
        "  # from segmentation_models_pytorch.unet.model import Unet\n",
        "\n",
        "  # Dynamically import the UNet class from unet.model\n",
        "  try:\n",
        "      unet_model = import_module('segmentation_models_pytorch.unet.model')\n",
        "      UNet = getattr(unet_model, 'Unet')  # or 'UNet' if spelled that way\n",
        "  except ModuleNotFoundError as e:\n",
        "      print(f\"Error importing the Unet model: {e}\")\n",
        "      sys.exit(1)\n",
        "  except AttributeError:\n",
        "      print(\"Error: The 'Unet' class was not found in 'model.py'.\")\n",
        "      sys.exit(1)\n",
        "\n",
        "  model = UNet(encoder_name=\"resnet101\",\n",
        "      encoder_weights=None,\n",
        "      in_channels=3,\n",
        "      classes=1)\n",
        "\n",
        "  model.load_state_dict(\n",
        "      torch.load(os.path.join(weight_dir, 'unet4.pth'), map_location='cpu'),\n",
        "      )\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "0chd4Z3xKI5F",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing and saving to Drive"
      ],
      "metadata": {
        "id": "CxHrD4aSVfyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dir in [images_dir, masks_dir]:\n",
        "  for i, img_name in enumerate(os.listdir(dir)):\n",
        "    image_path = os.path.join(dir, img_name)\n",
        "    img = cv.imread(image_path)\n",
        "    resized_img = cv.resize(img, (256, 256), interpolation=cv.INTER_AREA)\n",
        "\n",
        "    cv.imwrite(os.path.join(resized_images_dir if \"images\" in dir else resized_masks_dir, img_name), resized_img)"
      ],
      "metadata": {
        "id": "U5scLgoUVU8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading"
      ],
      "metadata": {
        "id": "CslPzfOeWB5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_mask(mask_gray, invert_mask, mask_convention):\n",
        "    \"\"\"\n",
        "    Processes the input grayscale mask and ensures the output is always:\n",
        "    - Black foreground (0)\n",
        "    - White background (255)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    mask_gray : np.ndarray\n",
        "        The grayscale mask with pixel values in [0, 255].\n",
        "    invert_mask : bool\n",
        "        Whether to invert the mask (e.g., flip foreground and background).\n",
        "    mask_convention : {\"black_fg\", \"white_fg\"}\n",
        "        The input mask convention:\n",
        "        - \"black_fg\": Black=foreground, White=background.\n",
        "        - \"white_fg\": White=foreground, Black=background.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    mask_bin : np.ndarray\n",
        "        Binary mask where:\n",
        "        - Foreground is always black (0).\n",
        "        - Background is always white (255).\n",
        "    \"\"\"\n",
        "    # Step 1: Ensure input mask is binary (0 or 255)\n",
        "    if not np.all(np.isin(mask_gray, [0, 255])):\n",
        "        print(f\"[INFO] Non-binary mask detected. Thresholding...\")\n",
        "        mask_gray = np.where(mask_gray > 128, 255, 0).astype(np.uint8)\n",
        "\n",
        "    # Step 2: Handle input mask convention\n",
        "    if mask_convention == \"white_fg\":\n",
        "        # White=Foreground (255), Black=Background (0) => Convert to Black FG\n",
        "        mask_gray = 255 - mask_gray  # Flip 0 <-> 255\n",
        "    elif mask_convention != \"black_fg\":\n",
        "        raise ValueError(f\"Invalid mask_convention: {mask_convention}. Use 'black_fg' or 'white_fg'.\")\n",
        "\n",
        "    # Step 3: Handle inversion if required\n",
        "    if invert_mask:\n",
        "        mask_gray = 255 - mask_gray  # Flip 0 <-> 255 again\n",
        "\n",
        "    # Step 4: Ensure final output is binary with:\n",
        "    # Black foreground (0), White background (255)\n",
        "    return mask_gray"
      ],
      "metadata": {
        "id": "FT6yKxthckvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDatasetRGB(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset that reads RGB images and RGB masks from disk, processes the masks,\n",
        "    and ensures output ground-truth masks are always:\n",
        "    - Black foreground (0).\n",
        "    - White background (255).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        images_dir,\n",
        "        masks_dir,\n",
        "        invert_mask=False,\n",
        "        mask_convention=\"black_fg\",\n",
        "        transform=None,\n",
        "        debug_print=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.invert_mask = invert_mask\n",
        "        self.mask_convention = mask_convention.lower().strip()\n",
        "        self.transform = transform\n",
        "        self.debug_print = debug_print\n",
        "\n",
        "        # Collect filenames\n",
        "        self.image_names = sorted(os.listdir(images_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        image_path = os.path.join(self.images_dir, img_name)\n",
        "        mask_path = os.path.join(self.masks_dir, img_name)\n",
        "\n",
        "        # Load image\n",
        "        img_bgr = cv.imread(image_path, cv.IMREAD_COLOR)\n",
        "        if img_bgr is None:\n",
        "            raise FileNotFoundError(f\"Could not read image at {image_path}\")\n",
        "        img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)\n",
        "\n",
        "        # Load mask\n",
        "        mask_bgr = cv.imread(mask_path, cv.IMREAD_COLOR)\n",
        "        if mask_bgr is None:\n",
        "            raise FileNotFoundError(f\"Could not read mask at {mask_path}\")\n",
        "        mask_gray = cv.cvtColor(mask_bgr, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Preprocess mask\n",
        "        mask_bin = preprocess_mask(mask_gray, self.invert_mask, self.mask_convention)\n",
        "\n",
        "        # Apply augmentations if provided\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img_rgb, mask=mask_bin)\n",
        "            img_rgb = augmented[\"image\"]\n",
        "            mask_bin = augmented[\"mask\"]\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_tensor = torch.tensor(img_rgb, dtype=torch.float32).permute(2, 0, 1)\n",
        "        mask_tensor = torch.tensor(mask_bin, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.debug_print and idx < 1:\n",
        "            # Display debug information and visualization\n",
        "            print(f\"[DEBUG] Loading: {img_name}\")\n",
        "            print(\"  image shape:\", img_tensor.shape)\n",
        "            print(\"  mask shape: \", mask_tensor.shape)\n",
        "            print(\"  unique mask values:\", torch.unique(mask_tensor))\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(mask_gray, cmap=\"gray\")\n",
        "            plt.title(\"Original Grayscale Mask\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(mask_bin, cmap=\"gray\", vmin=0, vmax=255)\n",
        "            plt.title(\"Processed Binary Mask (0=Black FG, 255=White BG)\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        return img_tensor, mask_tensor"
      ],
      "metadata": {
        "id": "jUKvkMc8jHPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(\n",
        "    images_dir,\n",
        "    masks_dir,\n",
        "    invert_mask=False,\n",
        "    mask_convention=\"black_fg\",\n",
        "    batch_size=32,\n",
        "    debug_print=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates a DataLoader for the SegmentationDatasetRGB.\n",
        "    \"\"\"\n",
        "    dataset = SegmentationDatasetRGB(\n",
        "        images_dir=images_dir,\n",
        "        masks_dir=masks_dir,\n",
        "        invert_mask=invert_mask,\n",
        "        mask_convention=mask_convention,\n",
        "        transform=None,     # or your augmentation\n",
        "        debug_print=debug_print\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "K2LMtcnplDfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix"
      ],
      "metadata": {
        "id": "jZJg1-l9q0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_confusion_matrix(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes confusion matrix for binary segmentation.\n",
        "    y_true and y_pred must be binary masks of the same shape.\n",
        "    \"\"\"\n",
        "    # Flatten masks to 1D arrays\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    # Compute confusion matrix elements\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "\n",
        "    return np.array([[TN, FP], [FN, TP]])\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix using Seaborn heatmap.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Aggregated Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aKLo63VJq0G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics"
      ],
      "metadata": {
        "id": "7g-MPh0tg2OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculates accuracy, precision, recall, F1-score, and IoU for the foreground class only.\n",
        "    Adds per-class metrics for both background and foreground.\n",
        "    \"\"\"\n",
        "    # Squeeze dimensions if necessary\n",
        "    if y_true.ndim == 3 and y_true.shape[0] == 1:\n",
        "        y_true = y_true[0]\n",
        "    if y_pred.ndim == 3 and y_pred.shape[0] == 1:\n",
        "        y_pred = y_pred[0]\n",
        "\n",
        "    # Ensure binary ground truth and predictions\n",
        "    y_true_bin = (y_true == 0).astype(np.uint8)\n",
        "    y_pred_bin = (y_pred <= threshold).astype(np.uint8)\n",
        "\n",
        "    # Debugging information\n",
        "    print(\"Unique values in ground truth (binary):\", np.unique(y_true_bin))\n",
        "    print(\"Unique values in predicted mask (binary):\", np.unique(y_pred_bin))\n",
        "\n",
        "    # Compute True Positives (TP), False Positives (FP), False Negatives (FN), True Negatives (TN)\n",
        "    TP = np.logical_and(y_pred_bin == 1, y_true_bin == 1).sum()\n",
        "    FP = np.logical_and(y_pred_bin == 1, y_true_bin == 0).sum()\n",
        "    FN = np.logical_and(y_pred_bin == 0, y_true_bin == 1).sum()\n",
        "    TN = np.logical_and(y_pred_bin == 0, y_true_bin == 0).sum()\n",
        "\n",
        "    # Per-class precision and recall\n",
        "    precision_bg = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
        "    recall_bg = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    precision_fg = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall_fg = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    # F1-score (foreground only)\n",
        "    f1_fg = 2 * (precision_fg * recall_fg) / (precision_fg + recall_fg) if (precision_fg + recall_fg) > 0 else 0\n",
        "\n",
        "    # IoU (foreground only)\n",
        "    iou_fg = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
        "\n",
        "    # IoU (background)\n",
        "    iou_bg = TN / (TN + FP + FN) if (TN + FP + FN) > 0 else 0\n",
        "\n",
        "    # Balanced accuracy\n",
        "    balanced_accuracy = (recall_bg + recall_fg) / 2\n",
        "\n",
        "    return precision_bg, recall_bg, precision_fg, recall_fg, f1_fg, iou_fg, iou_bg, balanced_accuracy"
      ],
      "metadata": {
        "id": "fPzPlE6Zg4L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_and_calculate_statistics(\n",
        "    model,\n",
        "    dataloader,\n",
        "    device=\"cpu\",\n",
        "    threshold=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Loops over the entire dataset in 'dataloader',\n",
        "    does inference, and calculates accuracy, precision, recall, f1, iou.\n",
        "    Returns dict of mean metrics and aggregated confusion matrix.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    metrics_dict = {\n",
        "        \"precision_bg\":  [],\n",
        "        \"recall_bg\":     [],\n",
        "        \"precision_fg\":  [],\n",
        "        \"recall_fg\":     [],\n",
        "        \"f1\":            [],\n",
        "        \"iou_fg\":        [],\n",
        "        \"iou_bg\":        [],\n",
        "        \"balanced_acc\":  []\n",
        "    }\n",
        "\n",
        "    # Initialize aggregated confusion matrix\n",
        "    total_cm = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)  # shape (B,1,H,W)\n",
        "            preds   = torch.sigmoid(outputs).cpu().numpy()  # => [0..1]\n",
        "            masks   = masks.cpu().numpy()                   # shape (B,1,H,W)\n",
        "\n",
        "            # Debug information\n",
        "            print(\"Preds min:\", preds.min(), \"max:\", preds.max())\n",
        "            print(\"Unique values in ground truth masks:\", np.unique(masks))\n",
        "\n",
        "            # Visualize raw ground truth and predictions for debugging\n",
        "            for i in range(len(masks)):\n",
        "                plt.figure(figsize=(10, 5))\n",
        "\n",
        "                plt.subplot(1, 3, 1)\n",
        "                img_display = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "                # Normalize image display if needed\n",
        "                if img_display.max() > 1:\n",
        "                    img_display = img_display / 255.0\n",
        "                plt.imshow(img_display, cmap=\"gray\")\n",
        "                plt.title(\"Originali nuotrauka\")\n",
        "\n",
        "                plt.subplot(1, 3, 2)\n",
        "                plt.imshow(masks[i, 0], cmap=\"gray\")\n",
        "                plt.title(\"Etaloninė kaukė\")\n",
        "\n",
        "                plt.subplot(1, 3, 3)\n",
        "                plt.imshow((preds[i, 0] > threshold).astype(np.uint8), cmap=\"gray\")\n",
        "                plt.title(\"Prognozuojama kaukė\")\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "            # Per-sample\n",
        "            for i in range(len(masks)):\n",
        "                precision_bg, recall_bg, precision_fg, recall_fg, f1_fg, iou_fg, iou_bg, balanced_acc = calculate_metrics(\n",
        "                    y_true = masks[i],\n",
        "                    y_pred = preds[i],\n",
        "                    threshold = threshold\n",
        "                )\n",
        "                metrics_dict[\"precision_bg\"].append(precision_bg)\n",
        "                metrics_dict[\"recall_bg\"].append(recall_bg)\n",
        "                metrics_dict[\"precision_fg\"].append(precision_fg)\n",
        "                metrics_dict[\"recall_fg\"].append(recall_fg)\n",
        "                metrics_dict[\"f1\"].append(f1_fg)\n",
        "                metrics_dict[\"iou_fg\"].append(iou_fg)\n",
        "                metrics_dict[\"iou_bg\"].append(iou_bg)\n",
        "                metrics_dict[\"balanced_acc\"].append(balanced_acc)\n",
        "\n",
        "                # Compute confusion matrix for this sample\n",
        "                cm = compute_confusion_matrix(\n",
        "                    y_true = (masks[i] == 0).astype(np.uint8),\n",
        "                    y_pred = (preds[i] <= threshold).astype(np.uint8)\n",
        "                )\n",
        "                total_cm += cm  # Aggregate confusion matrix\n",
        "\n",
        "    # Mean metrics\n",
        "    mean_metrics = {k: float(np.mean(v)) for k, v in metrics_dict.items()}\n",
        "\n",
        "    return mean_metrics, total_cm"
      ],
      "metadata": {
        "id": "8uqrFBs9z-fo"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing"
      ],
      "metadata": {
        "id": "vGQCEjo0WhQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_prediction(\n",
        "    img_tensor,\n",
        "    mask_tensor,\n",
        "    pred_tensor,\n",
        "    threshold=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Shows side by side: Original Image, Ground-Truth Mask, Predicted Mask.\n",
        "    - img_tensor:  (3,H,W) in float32\n",
        "    - mask_tensor: (1,H,W) in {0,1}\n",
        "    - pred_tensor: (1,H,W) in [0..1]\n",
        "    \"\"\"\n",
        "    img_np  = img_tensor.detach().cpu().numpy()\n",
        "    mask_np = mask_tensor.detach().cpu().numpy()\n",
        "    pred_np = pred_tensor.detach().cpu().numpy()\n",
        "\n",
        "    # Squeeze\n",
        "    if img_np.ndim == 3 and img_np.shape[0] == 3:\n",
        "        img_np = np.transpose(img_np, (1,2,0))  # => (H,W,3)\n",
        "    if mask_np.ndim == 3 and mask_np.shape[0] == 1:\n",
        "        mask_np = mask_np[0]\n",
        "    if pred_np.ndim == 3 and pred_np.shape[0] == 1:\n",
        "        pred_np = pred_np[0]\n",
        "\n",
        "    # Binarize\n",
        "    pred_bin = (pred_np > threshold).astype(np.uint8)\n",
        "\n",
        "    # Scale image for display if in [0..255]\n",
        "    if img_np.max() > 1:\n",
        "        img_display = img_np / 255.0\n",
        "    else:\n",
        "        img_display = img_np\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
        "    # Original\n",
        "    axes[0].imshow(img_display)\n",
        "    axes[0].set_title(\"Originali nuotrauka\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Ground Truth\n",
        "    axes[1].imshow(mask_np, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    axes[1].set_title(\"Teisinga kaukė\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # Prediction\n",
        "    axes[2].imshow(pred_bin, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    axes[2].set_title(\"Prognozuojama kaukė\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize_batch(\n",
        "    model,\n",
        "    dataloader,\n",
        "    device=\"cpu\",\n",
        "    threshold=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Displays the first sample of the first batch:\n",
        "    (image, ground-truth mask, predicted mask).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    images, masks = next(iter(dataloader))\n",
        "    images = images.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs).cpu().numpy()  # shape (B,1,H,W)\n",
        "\n",
        "    idx = 0\n",
        "    img_tensor  = images[idx].cpu()   # (3,H,W)\n",
        "    mask_tensor = masks[idx].cpu()    # (1,H,W)\n",
        "    pred_tensor = torch.from_numpy(preds[idx])  # (1,H,W)\n",
        "\n",
        "    visualize_prediction(img_tensor, mask_tensor, pred_tensor, threshold=threshold)"
      ],
      "metadata": {
        "id": "9piD0xQVWZ6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executing and table creating"
      ],
      "metadata": {
        "id": "4HB1xk9AWtwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # You must provide the paths to your images and masks.\n",
        "    # Each must have matching filenames (e.g. \"001.png\" for both).\n",
        "    images_dir = resized_images_dir\n",
        "    masks_dir  = resized_masks_dir\n",
        "\n",
        "\n",
        "    # If your model was trained on black=foreground(0),\n",
        "    # but your masks are actually white=foreground(255),\n",
        "    # you might do invert_mask=False + mask_convention=\"white_fg\", etc.\n",
        "    invert_mask = False\n",
        "    mask_convention = \"white_fg\"\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = get_dataloader(\n",
        "        images_dir=images_dir,\n",
        "        masks_dir=masks_dir,\n",
        "        invert_mask=invert_mask,\n",
        "        mask_convention=mask_convention,\n",
        "        batch_size=4,\n",
        "        debug_print=True  # prints debug info for the first item\n",
        "    )\n",
        "\n",
        "    # 2) Create or load your model\n",
        "    model = create_model()\n",
        "    # If you have pretrained weights, load them:\n",
        "    #   model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "\n",
        "    # 3) Visualize a sample batch\n",
        "    #    (Helps you confirm if the mask is indeed correct after inversion/binarization)\n",
        "    # Visualize first batch sample\n",
        "    #visualize_batch(model, dataloader, device=\"cpu\", threshold=0.5)\n",
        "\n",
        "    # Evaluate across dataset\n",
        "    metrics, aggregated_cm = test_model_and_calculate_statistics(\n",
        "        model=model,\n",
        "        dataloader=dataloader,\n",
        "        device=\"cpu\",\n",
        "        threshold=0.1\n",
        "    )\n",
        "\n",
        "\n",
        "    # 5) Print the results\n",
        "    print(\"===== METRICS =====\")\n",
        "    for k,v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    # Plot aggregated confusion matrix\n",
        "    plot_confusion_matrix(aggregated_cm, class_names=[\"Background\", \"Foreground\"])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "CSqTODghiab3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate  # Optional, for a nice CLI table\n",
        "\n",
        "def print_metrics_table(metrics_dict):\n",
        "    \"\"\"\n",
        "    Print metrics in a tabular format using pandas DataFrame.\n",
        "    \"\"\"\n",
        "    # Create a DataFrame from the metrics dictionary\n",
        "    metrics_df = pd.DataFrame([metrics_dict])\n",
        "\n",
        "    # Print as a table\n",
        "    print(\"Metrics Table:\")\n",
        "    print(tabulate(metrics_df, headers=\"keys\", tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "# Example Usage in Model Testing\n",
        "mean_metrics = {\n",
        "    #\"Accuracy\": 0.9984041124064632,\n",
        "    \"Precision\": 0.0910,\n",
        "    \"Recall\": 0.0205,\n",
        "    #\"F1-Score\": 0.9991957977679148,\n",
        "    \"IoU\": 0.0190\n",
        "}\n",
        "\n",
        "# Call the function to display metrics\n",
        "print_metrics_table(mean_metrics)"
      ],
      "metadata": {
        "id": "qQOYXH7TBQDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f470db-212b-4640-de30-bce8d921399a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "+----+-------------+----------+-------+\n",
            "|    |   Precision |   Recall |   IoU |\n",
            "+====+=============+==========+=======+\n",
            "|  0 |       0.091 |   0.0205 | 0.019 |\n",
            "+----+-------------+----------+-------+\n"
          ]
        }
      ]
    }
  ]
}