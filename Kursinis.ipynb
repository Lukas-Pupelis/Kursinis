{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mdsScBENtXql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "eee2abd9-6dcb-4878-ec3e-9c56b00fd368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretrainedmodels\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (0.20.1+cu121)\n",
            "Collecting munch (from pretrainedmodels)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pretrainedmodels) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pretrainedmodels) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->pretrainedmodels) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pretrainedmodels) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pretrainedmodels) (3.0.2)\n",
            "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=46da979ba52e35d6f743ad9508bc090d48436bf6ba6c33b7e05c57879bbe9b4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-4.0.0 pretrainedmodels-0.7.4\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=f180352ea2564c10650f190f7d69220b119315f546f2328fcfca4f18d528a111\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
        "from scipy.stats import ttest_rel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install pretrainedmodels\n",
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive_dir = drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp5XYW98ubsH",
        "outputId": "595caae9-ea3e-473a-cac7-44702be7355c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/mp'\n",
        "weight_dir = '/content/drive/My Drive/clam_weights/pre-trained_weights'\n",
        "model_dir = '/content/drive/My Drive/MP-Net/src/segmentation_models/segmentation_models_pytorch'\n",
        "root_dir = \"/content/drive/My Drive/MP-Net/src/segmentation_models\"\n",
        "images_dir = os.path.join(data_dir, 'images')\n",
        "masks_dir = os.path.join(data_dir, 'masks')\n",
        "unet_dir = os.path.join(model_dir, 'unet')\n",
        "resized_images_dir = os.path.join(data_dir, 'resized_images')\n",
        "resized_masks_dir = os.path.join(data_dir, 'resized_masks')\n",
        "inverted_resized_masks_dir = os.path.join(data_dir, 'inverted_resized_masks')"
      ],
      "metadata": {
        "id": "V-mE15StuCjW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "yTSRfWJZliMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from importlib import import_module\n",
        "\n",
        "if root_dir not in sys.path:\n",
        "    sys.path.append(root_dir)\n",
        "\n",
        "# 3. Check existence\n",
        "if not os.path.isdir(unet_dir):\n",
        "    print(f\"Error: The 'unet' directory was not found at '{unet_dir}'.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "from segmentation_models_pytorch.unet.model import Unet\n",
        "\n",
        "# Dynamically import the UNet class from unet.model\n",
        "try:\n",
        "    unet_model = import_module('segmentation_models_pytorch.unet.model')\n",
        "    UNet = getattr(unet_model, 'Unet')  # or 'UNet' if spelled that way\n",
        "except ModuleNotFoundError as e:\n",
        "    print(f\"Error importing the Unet model: {e}\")\n",
        "    sys.exit(1)\n",
        "except AttributeError:\n",
        "    print(\"Error: The 'Unet' class was not found in 'model.py'.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "model = UNet(encoder_name=\"resnet101\",     # <-- Must match your checkpoint’s encoder\n",
        "    encoder_weights=None,         # or \"imagenet\" if that was used\n",
        "    in_channels=3,                # checkpoint also shows 3-channel input (conv1 has shape [64,3,7,7])\n",
        "    classes=1)                     # checkpoint’s segmentation head has out_channels=1\n",
        "\n",
        "#model_dict = model.load_state_dict(torch.load(os.path.join(weight_dir,'unet4.pth'), map_location='cpu'), strict=False)\n",
        "\n",
        "#checkpoint = torch.load(os.path.join(weight_dir, 'unet4.pth'), map_location='cpu')\n",
        "#print(checkpoint.keys())  # see what’s inside\n",
        "\n",
        "model.load_state_dict(\n",
        "    torch.load(os.path.join(weight_dir, 'unet4.pth'), map_location='cpu'),\n",
        "    )\n",
        "\n",
        "# Set to evaluation mode (if using for inference)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0chd4Z3xKI5F",
        "outputId": "cdb8b39a-5afc-44e5-b6d4-b9e4b22c53ac",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-dbb2f5fdd7f8>:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(os.path.join(weight_dir, 'unet4.pth'), map_location='cpu'),\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (encoder): ResNetEncoder(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): UnetDecoder(\n",
              "    (center): Identity()\n",
              "    (blocks): ModuleList(\n",
              "      (0): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (segmentation_head): SegmentationHead(\n",
              "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Identity()\n",
              "    (2): Activation(\n",
              "      (activation): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing and saving to Drive"
      ],
      "metadata": {
        "id": "CxHrD4aSVfyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dir in [images_dir, masks_dir]:\n",
        "  for i, img_name in enumerate(os.listdir(dir)):\n",
        "    image_path = os.path.join(dir, img_name)\n",
        "    img = cv.imread(image_path)\n",
        "    resized_img = cv.resize(img, (256, 256), interpolation=cv.INTER_AREA)\n",
        "\n",
        "    cv.imwrite(os.path.join(resized_images_dir if \"images\" in dir else resized_masks_dir, img_name), resized_img)"
      ],
      "metadata": {
        "id": "U5scLgoUVU8v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ],
      "metadata": {
        "id": "8ArWasYtVvfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(img, cmap='gray'):\n",
        "  plt.imshow(img, cmap=cmap)\n",
        "  plt.show()\n",
        "\n",
        "def show_all_images(*images):\n",
        "  fig = plt.figure(figsize=(10, 7))\n",
        "  # setting values to rows and column variables\n",
        "  rows = 1\n",
        "  columns = len(images)\n",
        "  for i, image in enumerate(images):\n",
        "    # Adds a subplot at the 1st position\n",
        "    fig.add_subplot(rows, columns, i + 1)\n",
        "\n",
        "    # showing image\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "def show_images(labels, *images):\n",
        "  fig = plt.figure(figsize=(10, 7))\n",
        "  # setting values to rows and column variables\n",
        "  rows = 1\n",
        "  columns = len(images)\n",
        "\n",
        "  for i, image in enumerate(images):\n",
        "    # Adds a subplot at the 1st position\n",
        "    fig.add_subplot(rows, columns, i + 1)\n",
        "\n",
        "    # showing image\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(labels[i] if i + 1 <= len(labels) else i)"
      ],
      "metadata": {
        "id": "wz8rmUxsVWHL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def save_numpy_as_image(array, path):\n",
        "    \"\"\"\n",
        "    Saves a numpy array as an image.\n",
        "\n",
        "    Parameters:\n",
        "        array (numpy.ndarray): The image data as a numpy array.\n",
        "        path (str): The path where the image will be saved.\n",
        "    \"\"\"\n",
        "    # If the image is binary (i.e., has a shape like (256, 256, 1)),\n",
        "    # we should first remove the singleton dimension before saving it\n",
        "    if array.ndim == 3 and array.shape[-1] == 1:\n",
        "        array = array.squeeze(-1)\n",
        "\n",
        "    # Convert the numpy array to a PIL image\n",
        "    image = Image.fromarray(np.uint8(array * 255))\n",
        "\n",
        "    # Save the image\n",
        "    image.save(path)\n",
        "\n",
        "    print(f\"Image saved as {path}\")"
      ],
      "metadata": {
        "id": "rPiMePSLVem_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverting masks for the model"
      ],
      "metadata": {
        "id": "R24AmFkmvvVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Define the folder containing the images and the output folder\n",
        "input_folder = resized_masks_dir\n",
        "output_folder = inverted_resized_masks_dir\n",
        "\n",
        "# Loop through all files in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    # Check if the file is an image\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        try:\n",
        "            # Load the image\n",
        "            image = Image.open(input_path).convert(\"L\")  # Convert to grayscale\n",
        "\n",
        "            # Invert the colors\n",
        "            inverted_image = ImageOps.invert(image)\n",
        "\n",
        "            # Save the inverted image to the output folder\n",
        "            inverted_image.save(output_path)\n",
        "\n",
        "            print(f\"Processed: {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {filename}: {e}\")\n",
        "\n",
        "print(\"Batch processing completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "74EB0MP7v2cB",
        "outputId": "e9cb7f02-a193-4577-e897-c7f1945d1a7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: 20211223105352.jpg\n",
            "Processed: 20211223105328.jpg\n",
            "Processed: 20211223105558.jpg\n",
            "Processed: 20211223105246.jpg\n",
            "Processed: 20211223105413.jpg\n",
            "Processed: 20211223105341.jpg\n",
            "Processed: 20211223105115.jpg\n",
            "Processed: 20211223105218.jpg\n",
            "Processed: 20211223105043.jpg\n",
            "Processed: 20211223105434.jpg\n",
            "Processed: 20211223105234.jpg\n",
            "Processed: 20211223105511.jpg\n",
            "Processed: 20211223105604.jpg\n",
            "Processed: 20211223105958.jpg\n",
            "Processed: 20211223105753.jpg\n",
            "Processed: 20211223110033.jpg\n",
            "Processed: 20211223110228.jpg\n",
            "Processed: 20211223105651.jpg\n",
            "Processed: 20211223105854.jpg\n",
            "Processed: 20211223105906.jpg\n",
            "Processed: 20211223105713.jpg\n",
            "Processed: 20211223110027.jpg\n",
            "Processed: 20211223110056.jpg\n",
            "Processed: 20211223110141.jpg\n",
            "Processed: 20211223110252.jpg\n",
            "Processed: 20211223105822.jpg\n",
            "Processed: 20211223110007.jpg\n",
            "Processed: 20211223105835.jpg\n",
            "Processed: 20211223110044.jpg\n",
            "Processed: 20211223105616.jpg\n",
            "Processed: 20211223105845.jpg\n",
            "Processed: 20211223110152.jpg\n",
            "Processed: 20211223105723.jpg\n",
            "Processed: 20211223105945.jpg\n",
            "Processed: 20211223105805.jpg\n",
            "Processed: 20211223110810.jpg\n",
            "Processed: 20211223110206.jpg\n",
            "Processed: 20211223110538.jpg\n",
            "Processed: 20211223111010.jpg\n",
            "Processed: 20211223110753.jpg\n",
            "Processed: 20211223110302.jpg\n",
            "Processed: 20211223110955.jpg\n",
            "Processed: 20211223110824.jpg\n",
            "Processed: 20211223110606.jpg\n",
            "Processed: 20211223110705.jpg\n",
            "Processed: 20211223111025.jpg\n",
            "Processed: 20211223110633.jpg\n",
            "Processed: 20211223110454.jpg\n",
            "Processed: 20211223110716.jpg\n",
            "Processed: 20211223110732.jpg\n",
            "Processed: 20211223110429.jpg\n",
            "Processed: 20211223110614.jpg\n",
            "Processed: 20211223110657.jpg\n",
            "Processed: 20211223110848.jpg\n",
            "Processed: 20211223110508.jpg\n",
            "Processed: 20211223110545.jpg\n",
            "Processed: 20211223111041.jpg\n",
            "Processed: 20211223110447.jpg\n",
            "Processed: 20211223110940.jpg\n",
            "Processed: 20211223110903.jpg\n",
            "Processed: 20211223111054.jpg\n",
            "Processed: 20211223111423.jpg\n",
            "Processed: 20211223111520.jpg\n",
            "Processed: 20211223111539.jpg\n",
            "Processed: 20211223111411.jpg\n",
            "Processed: 20211223111130.jpg\n",
            "Processed: 20211223111154.jpg\n",
            "Processed: 20211223111145.jpg\n",
            "Processed: 20211223111341.jpg\n",
            "Processed: 20211223111430.jpg\n",
            "Processed: 20211223111310.jpg\n",
            "Processed: 20211223111253.jpg\n",
            "Processed: 20211223111234.jpg\n",
            "Processed: 20211223111243.jpg\n",
            "Processed: 20211223111322.jpg\n",
            "Processed: 20211223111205.jpg\n",
            "Processed: 20211223111215.jpg\n",
            "Processed: 20211223111435.jpg\n",
            "Processed: 20211223111110.jpg\n",
            "Processed: 20211223111258.jpg\n",
            "Processed: 20211223111457.jpg\n",
            "Processed: 20211223111510.jpg\n",
            "Processed: 20211223111159.jpg\n",
            "Processed: 20211223111811.jpg\n",
            "Processed: 20211223111949.jpg\n",
            "Processed: 20211223112206.jpg\n",
            "Processed: 20211223112038.jpg\n",
            "Processed: 20211223112135.jpg\n",
            "Processed: 20211223112025.jpg\n",
            "Processed: 20211223112152.jpg\n",
            "Processed: 20211223111931.jpg\n",
            "Processed: 20211223112233.jpg\n",
            "Processed: 20211223111846.jpg\n",
            "Processed: 20211223112048.jpg\n",
            "Processed: 20211223112141.jpg\n",
            "Processed: 20211223111800.jpg\n",
            "Processed: 20211223112057.jpg\n",
            "Processed: 20211223111754.jpg\n",
            "Processed: 20211223111909.jpg\n",
            "Processed: 20211223111727.jpg\n",
            "Processed: 20211223111743.jpg\n",
            "Processed: 20211223112019.jpg\n",
            "Processed: 20211223111859.jpg\n",
            "Processed: 20211223111836.jpg\n",
            "Processed: 20211223112011.jpg\n",
            "Processed: 20211223130151.jpg\n",
            "Processed: 20211223130528.jpg\n",
            "Processed: 20211223130509.jpg\n",
            "Processed: 20211223130534.jpg\n",
            "Processed: 20211223130106.jpg\n",
            "Processed: 20211223130626.jpg\n",
            "Processed: 20211223130412.jpg\n",
            "Processed: 20211223112256.jpg\n",
            "Processed: 20211223130616.jpg\n",
            "Processed: 20211223130428.jpg\n",
            "Processed: 20211223130546.jpg\n",
            "Processed: 20211223130436.jpg\n",
            "Processed: 20211223130500.jpg\n",
            "Processed: 20211223112310.jpg\n",
            "Processed: 20211223130216.jpg\n",
            "Processed: 20211223130246.jpg\n",
            "Processed: 20211223130235.jpg\n",
            "Processed: 20211223112240.jpg\n",
            "Processed: 20211223130324.jpg\n",
            "Processed: 20211223130311.jpg\n",
            "Processed: 20211223130204.jpg\n",
            "Processed: 20211223130338.jpg\n",
            "Processed: 20211223131103.jpg\n",
            "Processed: 20211223130557.jpg\n",
            "Processed: 20211223130951.jpg\n",
            "Processed: 20211223130801.jpg\n",
            "Processed: 20211223130936.jpg\n",
            "Processed: 20211223131012.jpg\n",
            "Processed: 20211223130641.jpg\n",
            "Processed: 20211223131118.jpg\n",
            "Processed: 20211223130821.jpg\n",
            "Processed: 20211223130750.jpg\n",
            "Processed: 20211223130732.jpg\n",
            "Processed: 20211223130717.jpg\n",
            "Processed: 20211223130957.jpg\n",
            "Processed: 20211223130842.jpg\n",
            "Processed: 20211223131031.jpg\n",
            "Processed: 20211223130914.jpg\n",
            "Processed: 20211223130812.jpg\n",
            "Processed: 20211223130848.jpg\n",
            "Processed: 20211223130659.jpg\n",
            "Processed: 20211223131132.jpg\n",
            "Processed: 20211223130900.jpg\n",
            "Processed: 20211223131024.jpg\n",
            "Processed: 20211223131047.jpg\n",
            "Processed: 20211223131208.jpg\n",
            "Processed: 20211223131832.jpg\n",
            "Processed: 20211223131404.jpg\n",
            "Processed: 20211223131335.jpg\n",
            "Processed: 20211223131356.jpg\n",
            "Processed: 20211223131652.jpg\n",
            "Processed: 20211223131659.jpg\n",
            "Processed: 20211223131414.jpg\n",
            "Processed: 20211223131715.jpg\n",
            "Processed: 20211223131317.jpg\n",
            "Processed: 20211223131457.jpg\n",
            "Processed: 20211223131143.jpg\n",
            "Processed: 20211223131152.jpg\n",
            "Processed: 20211223131725.jpg\n",
            "Processed: 20211223131252.jpg\n",
            "Processed: 20211223131311.jpg\n",
            "Processed: 20211223131449.jpg\n",
            "Processed: 20211223131237.jpg\n",
            "Processed: 20211223131229.jpg\n",
            "Processed: 20211223131303.jpg\n",
            "Processed: 20211223132326.jpg\n",
            "Processed: 20211223131739.jpg\n",
            "Processed: 20211223132839.jpg\n",
            "Processed: 20211223132929.jpg\n",
            "Processed: 20211223132518.jpg\n",
            "Processed: 20211223132453.jpg\n",
            "Processed: 20211223132812.jpg\n",
            "Processed: 20211223132347.jpg\n",
            "Processed: 20211223132445.jpg\n",
            "Processed: 20211223133020.jpg\n",
            "Processed: 20211223132952.jpg\n",
            "Processed: 20211223132745.jpg\n",
            "Processed: 20211223132940.jpg\n",
            "Processed: 20211223132337.jpg\n",
            "Processed: 20211223132417.jpg\n",
            "Processed: 20211223132536.jpg\n",
            "Processed: 20211223132407.jpg\n",
            "Processed: 20211223133005.jpg\n",
            "Processed: 20211223132757.jpg\n",
            "Processed: 20211223132434.jpg\n",
            "Processed: 20211223132917.jpg\n",
            "Processed: 20211223132554.jpg\n",
            "Processed: 20211223133029.jpg\n",
            "Processed: 20211223133043.jpg\n",
            "Processed: 20211223133256.jpg\n",
            "Processed: 20211223133614.jpg\n",
            "Processed: 20211223133239.jpg\n",
            "Processed: 20211223133513.jpg\n",
            "Processed: 20211223133226.jpg\n",
            "Processed: 20211223133308.jpg\n",
            "Processed: 20211223133208.jpg\n",
            "Processed: 20211223133316.jpg\n",
            "Processed: 20211223133055.jpg\n",
            "Processed: 20211223133342.jpg\n",
            "Processed: 20211223133629.jpg\n",
            "Processed: 20211223133331.jpg\n",
            "Processed: 20211223133249.jpg\n",
            "Processed: 20211223133605.jpg\n",
            "Processed: 20211223133137.jpg\n",
            "Processed: 20211223133109.jpg\n",
            "Processed: 20211223133130.jpg\n",
            "Processed: 20211223133535.jpg\n",
            "Processed: 20211223133551.jpg\n",
            "Processed: 20211223133426.jpg\n",
            "Processed: 20211223133148.jpg\n",
            "Processed: 20211223133354.jpg\n",
            "Processed: 20211223133843.jpg\n",
            "Processed: 20211223133827.jpg\n",
            "Processed: 20211223133635.jpg\n",
            "Processed: 20211223133655.jpg\n",
            "Processed: 20211223133952.jpg\n",
            "Processed: 20211223134035.jpg\n",
            "Processed: 20211223133727.jpg\n",
            "Processed: 20211223134014.jpg\n",
            "Processed: 20211223133707.jpg\n",
            "Processed: 20211223134058.jpg\n",
            "Processed: 20211223133644.jpg\n",
            "Processed: 20211223133938.jpg\n",
            "Processed: 20211223133959.jpg\n",
            "Processed: 20211223133856.jpg\n",
            "Processed: 20211223133820.jpg\n",
            "Processed: 20211223133738.jpg\n",
            "Processed: 20211223134045.jpg\n",
            "Processed: 20211223133814.jpg\n",
            "Processed: 20211223133922.jpg\n",
            "Processed: 20211223133716.jpg\n",
            "Processed: 20211223134110.jpg\n",
            "Processed: 20211223134020.jpg\n",
            "Processed: 20211223134345.jpg\n",
            "Processed: 20211223134337.jpg\n",
            "Processed: 20211223134503.jpg\n",
            "Processed: 20211223134319.jpg\n",
            "Processed: 20211223134251.jpg\n",
            "Processed: 20211223134619.jpg\n",
            "Processed: 20211223134145.jpg\n",
            "Processed: 20211223134357.jpg\n",
            "Processed: 20211223134350.jpg\n",
            "Processed: 20211223135228.jpg\n",
            "Processed: 20211223134510.jpg\n",
            "Processed: 20211223134216.jpg\n",
            "Processed: 20211223134327.jpg\n",
            "Processed: 20211223134305.jpg\n",
            "Processed: 20211223135217.jpg\n",
            "Processed: 20211223134603.jpg\n",
            "Processed: 20211223134548.jpg\n",
            "Processed: 20211223134235.jpg\n",
            "Processed: 20211223134736.jpg\n",
            "Processed: 20211223134721.jpg\n",
            "Processed: 20211223134452.jpg\n",
            "Processed: 20211223135130.jpg\n",
            "Processed: 20211223151916.jpg\n",
            "Processed: 20211223134408.jpg\n",
            "Processed: 20211223135555.jpg\n",
            "Processed: 20211223152120.jpg\n",
            "Processed: 20211223135314.jpg\n",
            "Processed: 20211223151855.jpg\n",
            "Processed: 20211223151831.jpg\n",
            "Processed: 20211223135451.jpg\n",
            "Processed: 20211223135530.jpg\n",
            "Processed: 20211223135439.jpg\n",
            "Processed: 20211223152011.jpg\n",
            "Processed: 20211223135518.jpg\n",
            "Processed: 20211223135644.jpg\n",
            "Processed: 20211223135729.jpg\n",
            "Processed: 20211223135355.jpg\n",
            "Processed: 20211223135636.jpg\n",
            "Processed: 20211223152032.jpg\n",
            "Processed: 20211223135659.jpg\n",
            "Processed: 20211223135333.jpg\n",
            "Processed: 20211223135420.jpg\n",
            "Processed: 20211223135340.jpg\n",
            "Processed: 20211223135244.jpg\n",
            "Processed: 20211223135654.jpg\n",
            "Processed: 20211223151910.jpg\n",
            "Processed: 20211223152451.jpg\n",
            "Processed: 20211223135432.jpg\n",
            "Processed: 20211223152621.jpg\n",
            "Processed: 20211223152201.jpg\n",
            "Processed: 20211223152529.jpg\n",
            "Processed: 20211223152240.jpg\n",
            "Processed: 20211223152145.jpg\n",
            "Processed: 20211223152328.jpg\n",
            "Processed: 20220103101533.jpg\n",
            "Processed: 20211223152222.jpg\n",
            "Processed: 20211223152442.jpg\n",
            "Processed: 20211223152554.jpg\n",
            "Processed: 20211223152429.jpg\n",
            "Processed: 20211223152633.jpg\n",
            "Processed: 20220103101526.jpg\n",
            "Processed: 20211223152544.jpg\n",
            "Processed: 20211223152256.jpg\n",
            "Processed: 20211223152312.jpg\n",
            "Processed: 20211223152714.jpg\n",
            "Processed: 20211223152250.jpg\n",
            "Processed: 20211223152724.jpg\n",
            "Processed: 20211223152520.jpg\n",
            "Processed: 20211223152412.jpg\n",
            "Processed: 20220103101758.jpg\n",
            "Processed: 20220103102031.jpg\n",
            "Processed: 20220103101627.jpg\n",
            "Processed: 20220103101602.jpg\n",
            "Processed: 20220103101837.jpg\n",
            "Processed: 20220103101823.jpg\n",
            "Processed: 20220103102142.jpg\n",
            "Processed: 20220103101906.jpg\n",
            "Processed: 20220103102116.jpg\n",
            "Processed: 20220103101610.jpg\n",
            "Processed: 20220103101737.jpg\n",
            "Processed: 20220103101702.jpg\n",
            "Processed: 20220103101916.jpg\n",
            "Processed: 20220103101710.jpg\n",
            "Processed: 20220103102152.jpg\n",
            "Processed: 20220103102058.jpg\n",
            "Processed: 20220103102203.jpg\n",
            "Processed: 20220103102046.jpg\n",
            "Processed: 20220103101651.jpg\n",
            "Processed: 20220103101947.jpg\n",
            "Processed: 20220103102126.jpg\n",
            "Processed: 20220103102106.jpg\n",
            "Processed: 20220103102022.jpg\n",
            "Processed: 20220103101953.jpg\n",
            "Processed: 20220103102013.jpg\n",
            "Processed: 20220103103148.jpg\n",
            "Processed: 20220103102722.jpg\n",
            "Processed: 20220103102916.jpg\n",
            "Processed: 20220103102945.jpg\n",
            "Processed: 20220103102959.jpg\n",
            "Processed: 20220103102839.jpg\n",
            "Processed: 20220103102926.jpg\n",
            "Processed: 20220103102759.jpg\n",
            "Processed: 20220103102932.jpg\n",
            "Processed: 20220103102715.jpg\n",
            "Processed: 20220103103102.jpg\n",
            "Processed: 20220103103022.jpg\n",
            "Processed: 20220103102806.jpg\n",
            "Processed: 20220103103113.jpg\n",
            "Processed: 20220103102615.jpg\n",
            "Processed: 20220103103204.jpg\n",
            "Processed: 20220103102640.jpg\n",
            "Processed: 20220103103005.jpg\n",
            "Processed: 20220103102815.jpg\n",
            "Processed: 20220103103210.jpg\n",
            "Processed: 20220103103039.jpg\n",
            "Processed: 20220103102734.jpg\n",
            "Processed: 20220103102621.jpg\n",
            "Processed: 20220103102744.jpg\n",
            "Processed: 20220103104346.jpg\n",
            "Processed: 20220103103255.jpg\n",
            "Processed: 20220103104416.jpg\n",
            "Processed: 20220103103722.jpg\n",
            "Processed: 20220103103238.jpg\n",
            "Processed: 20220103103812.jpg\n",
            "Processed: 20220103103220.jpg\n",
            "Processed: 20220103103227.jpg\n",
            "Processed: 20220103103615.jpg\n",
            "Processed: 20220103103633.jpg\n",
            "Processed: 20220103104403.jpg\n",
            "Processed: 20220103103555.jpg\n",
            "Processed: 20220103103802.jpg\n",
            "Processed: 20220103103643.jpg\n",
            "Processed: 20220103104356.jpg\n",
            "Processed: 20220103103737.jpg\n",
            "Processed: 20220103103658.jpg\n",
            "Processed: 20220103103758.jpg\n",
            "Processed: 20220103104529.jpg\n",
            "Processed: 20220103104557.jpg\n",
            "Processed: 20220103104505.jpg\n",
            "Processed: 20220103104727.jpg\n",
            "Processed: 20220103104813.jpg\n",
            "Processed: 20220103104438.jpg\n",
            "Processed: 20220103104537.jpg\n",
            "Processed: 20220103104549.jpg\n",
            "Processed: 20220103104450.jpg\n",
            "Processed: 20220103104836.jpg\n",
            "Processed: 20220103104909.jpg\n",
            "Processed: 20220103104745.jpg\n",
            "Processed: 20220103104640.jpg\n",
            "Processed: 20220103104626.jpg\n",
            "Processed: 20220103104703.jpg\n",
            "Processed: 20220103104513.jpg\n",
            "Processed: 20220103104904.jpg\n",
            "Processed: 20220103104830.jpg\n",
            "Processed: 20220103104738.jpg\n",
            "Processed: 20220103105121.jpg\n",
            "Processed: 20220103105045.jpg\n",
            "Processed: 20220103105112.jpg\n",
            "Processed: 20220103104430.jpg\n",
            "Processed: 20220103104915.jpg\n",
            "Processed: 20220103105056.jpg\n",
            "Processed: 20220103105030.jpg\n",
            "Processed: 20220103105000.jpg\n",
            "Processed: 20220103105130.jpg\n",
            "Processed: 20220103105103.jpg\n",
            "Batch processing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading"
      ],
      "metadata": {
        "id": "CslPzfOeWB5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_masks(images_dir, masks_dir):\n",
        "  images_arr = []\n",
        "  masks_arr = []\n",
        "  for i, img_name in enumerate(os.listdir(masks_dir)):\n",
        "    image_path = os.path.join(images_dir, img_name)\n",
        "    mask_path = image_path.replace(images_dir, masks_dir)\n",
        "    img = cv.imread(image_path)\n",
        "\n",
        "    if (os.path.isfile(mask_path)):\n",
        "      mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "      mask = np.expand_dims(mask, axis=-1)\n",
        "      images_arr.append(img)\n",
        "      masks_arr.append(mask)\n",
        "\n",
        "  return (images_arr, masks_arr)\n",
        "\n",
        "(raw_images, raw_masks) = load_images_and_masks(resized_images_dir, inverted_resized_masks_dir)"
      ],
      "metadata": {
        "id": "r_f4IelGTzoF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform = transform\n",
        "        self.image_names = os.listdir(masks_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        image_path = os.path.join(self.images_dir, img_name)\n",
        "        mask_path = os.path.join(self.masks_dir, img_name)\n",
        "\n",
        "        # Load image and mask\n",
        "        img = cv.imread(image_path)\n",
        "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "        mask = np.expand_dims(mask, axis=-1)  # Add channel dimension for mask\n",
        "\n",
        "        # Apply transformations if any\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img, mask=mask)\n",
        "            img = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)  # HWC -> CHW\n",
        "        mask = torch.tensor(mask, dtype=torch.float32).permute(2, 0, 1)  # HWC -> CHW\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "# Define dataset and DataLoader\n",
        "dataset = SegmentationDataset(resized_images_dir, inverted_resized_masks_dir)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "jUKvkMc8jHPH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics"
      ],
      "metadata": {
        "id": "7g-MPh0tg2OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for metrics calculation\n",
        "def calculate_metrics(y_true, y_pred, threshold=0.8):\n",
        "    \"\"\"\n",
        "    y_true: (1, H, W) or (H, W) in [0, 1]\n",
        "    y_pred: (1, H, W) or (H, W) in [0, 1] (probabilities)\n",
        "\n",
        "    1) Remove any leading channel dimension.\n",
        "    2) Threshold y_pred.\n",
        "    3) Flatten and compute metrics for binary segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Squeeze out leading channel if present (i.e., shape (1, H, W))\n",
        "    if y_true.ndim == 3 and y_true.shape[0] == 1:\n",
        "        y_true = y_true.squeeze(0)  # from (1, H, W) to (H, W)\n",
        "    if y_pred.ndim == 3 and y_pred.shape[0] == 1:\n",
        "        y_pred = y_pred.squeeze(0)  # from (1, H, W) to (H, W)\n",
        "\n",
        "    # Threshold predictions\n",
        "    y_pred_bin = (y_pred > threshold).astype(np.uint8)\n",
        "\n",
        "    # Flatten\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred_bin.flatten()\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_true_flat, y_pred_flat)\n",
        "    precision = precision_score(y_true_flat, y_pred_flat, average=\"binary\", zero_division=1)\n",
        "    recall = recall_score(y_true_flat, y_pred_flat, average=\"binary\", zero_division=1)\n",
        "    f1 = f1_score(y_true_flat, y_pred_flat, average=\"binary\", zero_division=1)\n",
        "    iou = jaccard_score(y_true_flat, y_pred_flat, average=\"binary\", zero_division=1)\n",
        "\n",
        "    return accuracy, precision, recall, f1, iou\n",
        "\n",
        "\n",
        "def test_model_and_calculate_statistics(model, dataloader, device=\"cuda\", threshold=0.8):\n",
        "    \"\"\"\n",
        "    Evaluate a binary segmentation model over the given dataloader.\n",
        "    Returns a dict with mean metrics across all batches/images.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Accumulate batch-wise metrics\n",
        "    metrics = {\n",
        "        \"accuracy\": [],\n",
        "        \"precision\": [],\n",
        "        \"recall\": [],\n",
        "        \"f1\": [],\n",
        "        \"iou\": []\n",
        "    }\n",
        "\n",
        "    # Disable gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            # Apply sigmoid to get probabilities in [0,1], then move to CPU\n",
        "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "            # Move masks to CPU and binarize them (assuming > 0 is foreground)\n",
        "            masks = masks.cpu().numpy()\n",
        "            masks_bin = (masks > 0).astype(np.uint8)  # shape (B, 1, H, W) or (B, H, W)\n",
        "\n",
        "            # Compute metrics for each image in the batch\n",
        "            for i in range(len(masks_bin)):\n",
        "                acc, prec, rec, f1, iou = calculate_metrics(\n",
        "                    masks_bin[i],\n",
        "                    preds[i],  # shape (1, H, W) or (H, W)\n",
        "                    threshold=threshold\n",
        "                )\n",
        "                metrics[\"accuracy\"].append(acc)\n",
        "                metrics[\"precision\"].append(prec)\n",
        "                metrics[\"recall\"].append(rec)\n",
        "                metrics[\"f1\"].append(f1)\n",
        "                metrics[\"iou\"].append(iou)\n",
        "\n",
        "    # Mean metrics across the entire dataset\n",
        "    mean_metrics = {key: np.mean(value) for key, value in metrics.items()}\n",
        "    return mean_metrics\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fPzPlE6Zg4L9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing"
      ],
      "metadata": {
        "id": "vGQCEjo0WhQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_sample(image, mask_bin, pred_bin):\n",
        "    \"\"\"\n",
        "    image:  Tensor or NumPy array of shape (C, H, W) or (H, W).\n",
        "    mask_bin: (H, W) in {0,1}.\n",
        "    pred_bin: (H, W) in {0,1}.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert PyTorch tensor to NumPy if needed\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = image.cpu().numpy()\n",
        "\n",
        "    # If image has shape (C, H, W), handle channels:\n",
        "    if image.ndim == 3:\n",
        "        if image.shape[0] == 1:\n",
        "            # Single channel: squeeze out the C dimension\n",
        "            image = image.squeeze(0)  # becomes (H, W)\n",
        "        elif image.shape[0] == 3:\n",
        "            # 3-channel: transpose to (H, W, 3) for RGB\n",
        "            image = np.transpose(image, (1, 2, 0))\n",
        "\n",
        "    # Now `image` is either (H, W) [grayscale] or (H, W, 3) [RGB].\n",
        "    # If it's (H, W, 1), we can squeeze once more:\n",
        "    if image.ndim == 3 and image.shape[2] == 1:\n",
        "        image = np.squeeze(image, axis=-1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # 1) Original Image\n",
        "    # If it's 2D, use cmap='gray'. If 3D, let matplotlib guess.\n",
        "    if image.ndim == 2:\n",
        "        axes[0].imshow(image, cmap=\"gray\")\n",
        "    else:\n",
        "        axes[0].imshow(image)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # 2) Ground-Truth Mask (H, W) in {0, 1}\n",
        "    axes[1].imshow(mask_bin, cmap=\"gray\")\n",
        "    axes[1].set_title(\"Ground-Truth Mask\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # 3) Predicted Mask (H, W) in {0, 1}\n",
        "    axes[2].imshow(pred_bin, cmap=\"gray\")\n",
        "    axes[2].set_title(\"Predicted Mask\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9piD0xQVWZ6s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_batch(model, dataloader, device=\"cuda\", threshold=0.5):\n",
        "    model.eval()\n",
        "\n",
        "    # Just take one batch\n",
        "    images, masks = next(iter(dataloader))\n",
        "    images = images.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "    # Visualize the first sample in the batch\n",
        "    idx = 0\n",
        "\n",
        "    # 1) Original image\n",
        "    img_np = images[idx]  # shape (C, H, W) on GPU\n",
        "    # 2) Ground truth mask\n",
        "    mask_np = masks[idx].cpu().numpy()  # shape could be (H, W) or (1, H, W)\n",
        "    mask_bin = (mask_np > 0).astype(np.uint8)  # ensure 0 or 1\n",
        "    # 3) Prediction\n",
        "    pred_np = preds[idx]  # shape (1, H, W) or (H, W)\n",
        "    if pred_np.ndim == 3 and pred_np.shape[0] == 1:\n",
        "        pred_np = pred_np.squeeze(0)\n",
        "    pred_bin = (pred_np > threshold).astype(np.uint8)\n",
        "\n",
        "    visualize_sample(img_np, mask_bin, pred_bin)"
      ],
      "metadata": {
        "id": "HvFfbx_wW0-p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Now call the function:\n",
        "visualize_batch(\n",
        "    model=model,\n",
        "    dataloader=dataloader,\n",
        "    device=\"cpu\",    # or \"cpu\", depending on your setup\n",
        "    threshold=0.5     # threshold for converting probabilities to 0/1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "vQOTJFr4YYST",
        "outputId": "e693293d-b407-4cd4-a286-e20c3889dc58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [83.0..228.0].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Invalid shape (1, 256, 256) for image data",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-43d181385ad5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Now call the function:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m visualize_batch(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-451300f111dd>\u001b[0m in \u001b[0;36mvisualize_batch\u001b[0;34m(model, dataloader, device, threshold)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mpred_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_np\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mvisualize_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-30591511f261>\u001b[0m in \u001b[0;36mvisualize_sample\u001b[0;34m(image, mask_bin, pred_bin)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# 2) Ground-Truth Mask (H, W) in {0, 1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ground-Truth Mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             return func(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5943\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5945\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5946\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5947\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_image_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# If just (M, N, 1), assume scalar and apply colormap.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid shape {A.shape} for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;31m# If the input data has values outside the valid range (after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 256, 256) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKkAAAGyCAYAAAAvapdBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPVNJREFUeJzt3X1wVfW9L/5PEiTBaiKKBKRRfKrWKwKCYlDbwznRTFUszrWl6AWkPtRT8SqplgeBiFSCD3jpVCwVtdjpVTh61fEKB2upHOuRW0eQ1ragFwHhckwALQkNCpqs3x/9uU+3CQqY7MXD6zWzZ8w337XXZ30mriHvfNd35yVJkgQAAAAApCg/7QIAAAAAQEgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAQM689NJLMXjw4DjmmGMiLy8vnnnmmc89ZsmSJXHmmWdGYWFhnHTSSTF37tx2rxOA3BNSAQAAOdPY2Bi9e/eOWbNm7db8tWvXxsUXXxyDBg2KFStWxM033xzXXHNNPP/88+1cKQC5lpckSZJ2EQAAwMEnLy8vnn766RgyZMgu54wdOzYWLFgQf/zjHzNj3/nOd2Lr1q2xaNGiHFQJQK50SLsAAACAXVm6dGlUVFRkjVVWVsbNN9/8mcft2LEjduzYkfm6ubk53n///TjqqKMiLy+vPUoFOKgkSRLbtm2LY445JvLz2+ZBPSEVe+z222+PKVOmxN4swps7d26MGjUq1q5dGz179mz74iJi3bp1cfzxx8fPf/7zuOqqq9rlHAAA5EZtbW2UlpZmjZWWlkZDQ0N88MEH0alTp1aPq6mpiSlTpuSiRICD2oYNG+LLX/5ym7yXkOog8qc//SlqamrixRdfjC1btsRRRx0VgwYNigkTJsR/+S//Je3ycm7JkiUxaNCgeOKJJ+Lyyy9PuxwAANrQ+PHjo6qqKvN1fX19HHvssbFhw4YoLi5OsTKAA0NDQ0OUlZXF4Ycf3mbvKaQ6SDz11FMxbNiwOPLII+Pqq6+O448/PtatWxcPP/xwPPnkkzFv3ry47LLLduu9Jk6cGOPGjdurOoYPHx7f+c53orCwcK+OBwDg4NKtW7eoq6vLGqurq4vi4uJdrqKKiCgsLGz135zFxcVCKoA21JaPUAupDgJvv/12DB8+PE444YR46aWX4uijj85876abborzzz8/hg8fHn/4wx/ihBNO2OX7NDY2xpe+9KXo0KFDdOiwdz86BQUFUVBQsFfHAgBw8CkvL4+FCxdmjb3wwgtRXl6eUkUAtJe22dmKfdo999wT27dvjwcffDAroIqI6NKlS/zsZz+LxsbGuPvuuzPjt99+e+Tl5cWf//znuOKKK6Jz585x3nnnZX3v733wwQfx3//7f48uXbrE4YcfHpdeemls3Lgx8vLy4vbbb8/Mmzt3buTl5cW6desyYz179oxLLrkkXn755Tj77LOjqKgoTjjhhPjFL36RdY73338/brnllujVq1ccdthhUVxcHN/4xjfi97//fRt16j+v7a233or/9t/+W5SUlMTRRx8dkyZNiiRJYsOGDfHNb34ziouLo1u3bjFjxoys43fu3BmTJ0+Ofv36RUlJSXzpS1+K888/P1588cUW53rvvfdi+PDhUVxcHEcccUSMHDkyfv/730deXl7MnTs3a+6qVavi8ssvjyOPPDKKioqif//+8eyzz7bZdQMA5Mpf//rXWLFiRaxYsSIiItauXRsrVqyI9evXR8TfHtMbMWJEZv71118fa9asiR/+8IexatWqeOCBB+Jf/uVfYsyYMWmUD0A7ElIdBP73//7f0bNnzzj//PNb/f7Xvva16NmzZyxYsKDF9771rW/F9u3bY9q0aXHttdfu8hxXXXVV/OQnP4mLLroo7rrrrujUqVNcfPHFu13j6tWr4/LLL48LLrggZsyYEZ07d46rrroq/vSnP2XmrFmzJp555pm45JJL4r777otbb7013njjjfj6178e//Ef/7Hb59odQ4cOjebm5pg+fXoMGDAgfvSjH8XMmTPjggsuiB49esRdd90VJ510Utxyyy3x0ksvZY5raGiIhx56KP7hH/4h7rrrrrj99ttj8+bNUVlZmfmHWMTfPl1m8ODB8fjjj8fIkSPjzjvvjHfffTdGjhzZopY//elPcc4558TKlStj3LhxMWPGjPjSl74UQ4YMiaeffrpNrxsAoL299tpr0bdv3+jbt29ERFRVVUXfvn1j8uTJERHx7rvvZgKriIjjjz8+FixYEC+88EL07t07ZsyYEQ899FBUVlamUj8A7SjhgLZ169YkIpJvfvObnznv0ksvTSIiaWhoSJIkSaqrq5OISIYNG9Zi7iff+8SyZcuSiEhuvvnmrHlXXXVVEhFJdXV1ZuznP/95EhHJ2rVrM2PHHXdcEhHJSy+9lBnbtGlTUlhYmPzgBz/IjH344YdJU1NT1jnWrl2bFBYWJnfccUfWWEQkP//5zz/zml988cUkIpInnniixbVdd911mbGPP/44+fKXv5zk5eUl06dPz4z/5S9/STp16pSMHDkya+6OHTuyzvOXv/wlKS0tTb773e9mxv7X//pfSUQkM2fOzIw1NTUl//iP/9ii9n/6p39KevXqlXz44YeZsebm5mTgwIHJySef/JnXCADA39TX1ycRkdTX16ddCsABoT3uq1ZSHeC2bdsWEfG5u+1/8v2Ghoas8euvv/5zz7Fo0aKIiPj+97+fNX7jjTfudp2nnXZa1kqvo48+Ok455ZRYs2ZNZqywsDDy8//2I9vU1BTvvfdeHHbYYXHKKafE8uXLd/tcu+Oaa67J/HdBQUH0798/kiSJq6++OjN+xBFHtKixoKAgOnbsGBF/Wy31/vvvx8cffxz9+/fPqnHRokVxyCGHZK1Oy8/PjxtuuCGrjvfffz9+85vfxLe//e3Ytm1bbNmyJbZs2RLvvfdeVFZWxv/9v/83Nm7c2KbXDgAAAGmwcfoB7pPw6ZOwald2FWYdf/zxn3uOd955J/Lz81vMPemkk3a7zmOPPbbFWOfOneMvf/lL5uvm5ub48Y9/HA888ECsXbs2mpqaMt876qijdvtce1NPSUlJFBUVRZcuXVqMv/fee1ljjz76aMyYMSNWrVoVH330UWb87/vzzjvvRPfu3ePQQw/NOvbTPVu9enUkSRKTJk2KSZMmtVrrpk2bokePHrt/cQAAALAPElId4EpKSqJ79+7xhz/84TPn/eEPf4gePXq0+Djez/pY37a0q0/8S5Ik89/Tpk2LSZMmxXe/+92YOnVqHHnkkZGfnx8333xzNDc3t3s9u1PjL3/5y7jqqqtiyJAhceutt0bXrl2joKAgampq4u23397jOj65rltuuWWX+y7sSRgIAAAA+yoh1UHgkksuiTlz5sTLL7+c+YS+v/fb3/421q1bF9/73vf26v2PO+64aG5ujrVr18bJJ5+cGV+9evVe19yaJ598MgYNGhQPP/xw1vjWrVtbrHBKy5NPPhknnHBCPPXUU1mfgFhdXZ0177jjjosXX3wxtm/fnrWa6tM9O+GEEyIi4pBDDomKiop2rBwAAADSZU+qg8Ctt94anTp1iu9973stHk17//334/rrr49DDz00br311r16/09W+DzwwANZ4z/5yU/2ruBdKCgoyFq1FBHxxBNP7FN7Mn2y2urv6/zd734XS5cuzZpXWVkZH330UcyZMycz1tzcHLNmzcqa17Vr1/iHf/iH+NnPfhbvvvtui/Nt3ry5LcsHAACA1FhJdRA4+eST49FHH40rr7wyevXqFVdffXUcf/zxsW7dunj44Ydjy5Yt8fjjj8eJJ564V+/fr1+/+K//9b/GzJkz47333otzzjkn/u3f/i3eeuutiIisFUVfxCWXXBJ33HFHjBo1KgYOHBhvvPFG/M//+T8zq432BZdcckk89dRTcdlll8XFF18ca9eujdmzZ8dpp50Wf/3rXzPzhgwZEmeffXb84Ac/iNWrV8epp54azz77bLz//vsRkd2zWbNmxXnnnRe9evWKa6+9Nk444YSoq6uLpUuXxv/7f/8vfv/73+f8OgEAAKCtCakOEt/61rfi1FNPjZqamkwwddRRR8WgQYNiwoQJcfrpp3+h9//FL34R3bp1i8cffzyefvrpqKioiPnz58cpp5wSRUVFbXINEyZMiMbGxnjsscdi/vz5ceaZZ8aCBQti3LhxbfL+beGqq66K2tra+NnPfhbPP/98nHbaafHLX/4ynnjiiViyZElmXkFBQSxYsCBuuummePTRRyM/Pz8uu+yyqK6ujnPPPTerZ6eddlq89tprMWXKlJg7d26899570bVr1+jbt29Mnjw5hasEAACAtpeXfPr5KWgjK1asiL59+8Yvf/nLuPLKK9MuZ7/wzDPPxGWXXRYvv/xynHvuuWmXAwBwwGhoaIiSkpKor69v8WFBAOy59riv2pOKNvHBBx+0GJs5c2bk5+fH1772tRQq2vd9umdNTU3xk5/8JIqLi+PMM89MqSoAAABIh8f9aBN33313LFu2LAYNGhQdOnSIf/3Xf41//dd/jeuuuy7KysrSLm+fdOONN8YHH3wQ5eXlsWPHjnjqqafilVdeiWnTpkWnTp3SLg8AAABySkhFmxg4cGC88MILMXXq1PjrX/8axx57bNx+++1x2223pV3aPusf//EfY8aMGfHcc8/Fhx9+GCeddFL85Cc/idGjR6ddGgAAAOScPakAyPLSSy/FPffcE8uWLYt33303nn766RgyZMhnHrNkyZKoqqqKP/3pT1FWVhYTJ06Mq666Kif1AsDusCcVQNuyJxUA7a6xsTF69+4ds2bN2q35a9eujYsvvjgGDRoUK1asiJtvvjmuueaaeP7559u5UgAA4EDicT8AsnzjG9+Ib3zjG7s9f/bs2XH88cfHjBkzIiLiq1/9arz88svxP/7H/4jKysr2KhMAADjACKkA+EKWLl0aFRUVWWOVlZVx88037/KYHTt2xI4dOzJfNzc3x/vvvx9HHXVU5OXltVepAAeNJEli27Ztccwxx0R+vocnANg/CKkA+EJqa2ujtLQ0a6y0tDQaGhrigw8+aPXTKmtqamLKlCm5KhHgoLVhw4b48pe/nHYZALBbhFQA5Nz48eOjqqoq83V9fX0ce+yxsWHDBpvZArSBhoaGKCsri8MPPzztUgBgtwmpAPhCunXrFnV1dVljdXV1UVxc3OoqqoiIwsLCKCwsbDFeXFwspAJoQx6hBmB/4gF1AL6Q8vLyWLx4cdbYCy+8EOXl5SlVBAAA7I+EVABk+etf/xorVqyIFStWRETE2rVrY8WKFbF+/fqI+NujeiNGjMjMv/7662PNmjXxwx/+MFatWhUPPPBA/Mu//EuMGTMmjfIBAID9lJAKgCyvvfZa9O3bN/r27RsREVVVVdG3b9+YPHlyRES8++67mcAqIuL444+PBQsWxAsvvBC9e/eOGTNmxEMPPRSVlZWp1A8AAOyf8pIkSdIuAoCDW0NDQ5SUlER9fb09qQDagPtqS3oC0Lba475qJRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAJBzs2bNip49e0ZRUVEMGDAgXn311c+cP3PmzDjllFOiU6dOUVZWFmPGjIkPP/wwR9UCkAtCKgAAIKfmz58fVVVVUV1dHcuXL4/evXtHZWVlbNq0qdX5jz32WIwbNy6qq6tj5cqV8fDDD8f8+fNjwoQJOa4cgPYkpAIAAHLqvvvui2uvvTZGjRoVp512WsyePTsOPfTQeOSRR1qd/8orr8S5554bV1xxRfTs2TMuvPDCGDZs2OeuvgJg/yKkAgAAcmbnzp2xbNmyqKioyIzl5+dHRUVFLF26tNVjBg4cGMuWLcuEUmvWrImFCxfGRRddtMvz7NixIxoaGrJeAOzbOqRdAAAAcPDYsmVLNDU1RWlpadZ4aWlprFq1qtVjrrjiitiyZUucd955kSRJfPzxx3H99dd/5uN+NTU1MWXKlDatHYD2ZSUVAACwT1uyZElMmzYtHnjggVi+fHk89dRTsWDBgpg6deoujxk/fnzU19dnXhs2bMhhxQDsDSupAACAnOnSpUsUFBREXV1d1nhdXV1069at1WMmTZoUw4cPj2uuuSYiInr16hWNjY1x3XXXxW233Rb5+S3/9l5YWBiFhYVtfwEAtBsrqQAAgJzp2LFj9OvXLxYvXpwZa25ujsWLF0d5eXmrx2zfvr1FEFVQUBAREUmStF+xAOSUlVQAAEBOVVVVxciRI6N///5x9tlnx8yZM6OxsTFGjRoVEREjRoyIHj16RE1NTUREDB48OO67777o27dvDBgwIFavXh2TJk2KwYMHZ8IqAPZ/QioAACCnhg4dGps3b47JkydHbW1t9OnTJxYtWpTZTH39+vVZK6cmTpwYeXl5MXHixNi4cWMcffTRMXjw4LjzzjvTugQA2kFeYn0sAClraGiIkpKSqK+vj+Li4rTLAdjvua+2pCcAbas97qv2pAIAAAAgdUIqAAAAAFInpAKghVmzZkXPnj2jqKgoBgwYEK+++upnzp85c2accsop0alTpygrK4sxY8bEhx9+mKNqAQCAA4GQCoAs8+fPj6qqqqiuro7ly5dH7969o7KyMjZt2tTq/MceeyzGjRsX1dXVsXLlynj44Ydj/vz5MWHChBxXDgAA7M+EVABkue++++Laa6+NUaNGxWmnnRazZ8+OQw89NB555JFW57/yyitx7rnnxhVXXBE9e/aMCy+8MIYNG/a5q68AAAD+npAKgIydO3fGsmXLoqKiIjOWn58fFRUVsXTp0laPGThwYCxbtiwTSq1ZsyYWLlwYF1100S7Ps2PHjmhoaMh6AQAAB7cOaRcAwL5jy5Yt0dTUFKWlpVnjpaWlsWrVqlaPueKKK2LLli1x3nnnRZIk8fHHH8f111//mY/71dTUxJQpU9q0dgAAYP9mJRUAX8iSJUti2rRp8cADD8Ty5cvjqaeeigULFsTUqVN3ecz48eOjvr4+89qwYUMOKwYAAPZFVlIBkNGlS5coKCiIurq6rPG6urro1q1bq8dMmjQphg8fHtdcc01ERPTq1SsaGxvjuuuui9tuuy3y81v+PaSwsDAKCwvb/gIAAID9lpVUAGR07Ngx+vXrF4sXL86MNTc3x+LFi6O8vLzVY7Zv394iiCooKIiIiCRJ2q9YAADggGIlFQBZqqqqYuTIkdG/f/84++yzY+bMmdHY2BijRo2KiIgRI0ZEjx49oqamJiIiBg8eHPfdd1/07ds3BgwYEKtXr45JkybF4MGDM2EVAADA5xFSAZBl6NChsXnz5pg8eXLU1tZGnz59YtGiRZnN1NevX5+1cmrixImRl5cXEydOjI0bN8bRRx8dgwcPjjvvvDOtSwAAAPZDeYlnMQBIWUNDQ5SUlER9fX0UFxenXQ7Afs99tSU9AWhb7XFftScVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAADk3a9as6NmzZxQVFcWAAQPi1Vdf/cz5W7dujRtuuCG6d+8ehYWF8ZWvfCUWLlyYo2oByIUOaRcAAAAcXObPnx9VVVUxe/bsGDBgQMycOTMqKyvjzTffjK5du7aYv3Pnzrjggguia9eu8eSTT0aPHj3inXfeiSOOOCL3xQPQboRUAABATt13331x7bXXxqhRoyIiYvbs2bFgwYJ45JFHYty4cS3mP/LII/H+++/HK6+8EoccckhERPTs2TOXJQOQAx73AwAAcmbnzp2xbNmyqKioyIzl5+dHRUVFLF26tNVjnn322SgvL48bbrghSktL4/TTT49p06ZFU1PTLs+zY8eOaGhoyHoBsG8TUgHQgn1CAGgvW7ZsiaampigtLc0aLy0tjdra2laPWbNmTTz55JPR1NQUCxcujEmTJsWMGTPiRz/60S7PU1NTEyUlJZlXWVlZm14HAG1PSAVAlk/2Camuro7ly5dH7969o7KyMjZt2tTq/E/2CVm3bl08+eST8eabb8acOXOiR48eOa4cgANVc3NzdO3aNR588MHo169fDB06NG677baYPXv2Lo8ZP3581NfXZ14bNmzIYcUA7A17UgGQxT4hALSnLl26REFBQdTV1WWN19XVRbdu3Vo9pnv37nHIIYdEQUFBZuyrX/1q1NbWxs6dO6Njx44tjiksLIzCwsK2LR6AdmUlFQAZudonBICDV8eOHaNfv36xePHizFhzc3MsXrw4ysvLWz3m3HPPjdWrV0dzc3Nm7K233oru3bu3GlABsH8SUgGQkat9QmxmC3Bwq6qqijlz5sSjjz4aK1eujH/+53+OxsbGzCreESNGxPjx4zPz//mf/znef//9uOmmm+Ktt96KBQsWxLRp0+KGG25I6xIAaAce9wPgC/n7fUIKCgqiX79+sXHjxrjnnnuiurq61WNqampiypQpOa4UgH3F0KFDY/PmzTF58uSora2NPn36xKJFizJ/JFm/fn3k5//n39PLysri+eefjzFjxsQZZ5wRPXr0iJtuuinGjh2b1iUA0A6EVABk5GqfkPHjx0dVVVXm64aGBp+6BHCQGT16dIwePbrV7y1ZsqTFWHl5efyf//N/2rkqANLkcT8AMnK1T0hhYWEUFxdnvQAAgIObkAqALPYJAQAA0uBxPwCy2CcEAABIQ16SJEnaRQBwcGtoaIiSkpKor6/36B9AG3BfbUlPANpWe9xXPe4HAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFAAAAQOqEVAAAAACkTkgFQKtmzZoVPXv2jKKiohgwYEC8+uqru3XcvHnzIi8vL4YMGdK+BQIAAAcUIRUALcyfPz+qqqqiuro6li9fHr17947KysrYtGnTZx63bt26uOWWW+L888/PUaUAAMCBQkgFQAv33XdfXHvttTFq1Kg47bTTYvbs2XHooYfGI488sstjmpqa4sorr4wpU6bECSeckMNqAQCAA4GQCoAsO3fujGXLlkVFRUVmLD8/PyoqKmLp0qW7PO6OO+6Irl27xtVXX/2559ixY0c0NDRkvQAAgIObkAqALFu2bImmpqYoLS3NGi8tLY3a2tpWj3n55Zfj4Ycfjjlz5uzWOWpqaqKkpCTzKisr+8J1A7B/sfchAJ8mpALgC9m2bVsMHz485syZE126dNmtY8aPHx/19fWZ14YNG9q5SgD2JfY+BKA1HdIuAIB9S5cuXaKgoCDq6uqyxuvq6qJbt24t5r/99tuxbt26GDx4cGasubk5IiI6dOgQb775Zpx44olZxxQWFkZhYWE7VA/A/uDv9z6MiJg9e3YsWLAgHnnkkRg3blyrx/z93oe//e1vY+vWrTmsGIBcsJIKgCwdO3aMfv36xeLFizNjzc3NsXjx4igvL28x/9RTT4033ngjVqxYkXldeumlMWjQoFixYoVH+QDIkou9DyPsfwiwP7KSCoAWqqqqYuTIkdG/f/84++yzY+bMmdHY2Jj5i/eIESOiR48eUVNTE0VFRXH66adnHX/EEUdERLQYB4DP2vtw1apVrR7zyd6HK1as2O3z1NTUxJQpU75IqQDkmJAKgBaGDh0amzdvjsmTJ0dtbW306dMnFi1alPmFYv369ZGfbzEuAO1vb/Y+jPjb/odVVVWZrxsaGqzuBdjHCakAaNXo0aNj9OjRrX5vyZIln3ns3Llz274gAA4Iudj7MML+hwD7I38GBwAAcsbehwDsipVUAABATtn7EIDWCKkAAICcsvchAK3JS5IkSbsIAA5uDQ0NUVJSEvX19VFcXJx2OQD7PffVlvQEoG21x33VnycAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCgAAAIDUCakAAAAASJ2QCoBWzZo1K3r27BlFRUUxYMCAePXVV3c5d86cOXH++edH586do3PnzlFRUfGZ8wEAAD5NSAVAC/Pnz4+qqqqorq6O5cuXR+/evaOysjI2bdrU6vwlS5bEsGHD4sUXX4ylS5dGWVlZXHjhhbFx48YcVw4AAOyv8pIkSdIuAoB9y4ABA+Kss86K+++/PyIimpubo6ysLG688cYYN27c5x7f1NQUnTt3jvvvvz9GjBjxufMbGhqipKQk6uvro7i4+AvXD3Cwc19tSU8A2lZ73FetpAIgy86dO2PZsmVRUVGRGcvPz4+KiopYunTpbr3H9u3b46OPPoojjzyy1e/v2LEjGhoasl4AAMDBTUgFQJYtW7ZEU1NTlJaWZo2XlpZGbW3tbr3H2LFj45hjjskKuv5eTU1NlJSUZF5lZWVfuG4AAGD/JqQCoE1Nnz495s2bF08//XQUFRW1Omf8+PFRX1+feW3YsCHHVQIAAPuaDmkXAMC+pUuXLlFQUBB1dXVZ43V1ddGtW7fPPPbee++N6dOnx69//es444wzdjmvsLAwCgsL26ReAADgwGAlFQBZOnbsGP369YvFixdnxpqbm2Px4sVRXl6+y+PuvvvumDp1aixatCj69++fi1IBAIADiJVUALRQVVUVI0eOjP79+8fZZ58dM2fOjMbGxhg1alRERIwYMSJ69OgRNTU1ERFx1113xeTJk+Oxxx6Lnj17ZvauOuyww+Kwww5L7ToAAID9h5AKgBaGDh0amzdvjsmTJ0dtbW306dMnFi1alNlMff369ZGf/5+LcX/605/Gzp074/LLL896n+rq6rj99ttzWToAALCfykuSJEm7CAAObg0NDVFSUhL19fVRXFycdjkA+z331Zb0BKBttcd91Z5UAAAAAKROSAUAAABA6oRUAABAzs2aNSt69uwZRUVFMWDAgHj11Vd3OXfOnDlx/vnnR+fOnaNz585RUVHxmfMB2D8JqQAAgJyaP39+VFVVRXV1dSxfvjx69+4dlZWVsWnTplbnL1myJIYNGxYvvvhiLF26NMrKyuLCCy+MjRs35rhyANqTjdMBSJ3NbAHa1r5+Xx0wYECcddZZcf/990dERHNzc5SVlcWNN94Y48aN+9zjm5qaonPnznH//ffHiBEjduuc+3pPAPY3Nk4HAAD2azt37oxly5ZFRUVFZiw/Pz8qKipi6dKlu/Ue27dvj48++iiOPPLIXc7ZsWNHNDQ0ZL0A2LcJqQAAgJzZsmVLNDU1RWlpadZ4aWlp1NbW7tZ7jB07No455pisoOvTampqoqSkJPMqKyv7QnUD0P6EVAAAwH5j+vTpMW/evHj66aejqKhol/PGjx8f9fX1mdeGDRtyWCUAe6ND2gUAAAAHjy5dukRBQUHU1dVljdfV1UW3bt0+89h77703pk+fHr/+9a/jjDPO+My5hYWFUVhY+IXrBSB3rKQCAABypmPHjtGvX79YvHhxZqy5uTkWL14c5eXluzzu7rvvjqlTp8aiRYuif//+uSgVgByzkgoAAMipqqqqGDlyZPTv3z/OPvvsmDlzZjQ2NsaoUaMiImLEiBHRo0ePqKmpiYiIu+66KyZPnhyPPfZY9OzZM7N31WGHHRaHHXZYatcBQNsSUgEAADk1dOjQ2Lx5c0yePDlqa2ujT58+sWjRosxm6uvXr4/8/P986OOnP/1p7Ny5My6//PKs96muro7bb789l6UD0I7ykiRJ0i4CgINbQ0NDlJSURH19fRQXF6ddDsB+z321JT0BaFvtcV+1JxUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUAAAAAqRNSAQAAAJA6IRUArZo1a1b07NkzioqKYsCAAfHqq69+5vwnnngiTj311CgqKopevXrFwoULc1QpAABwIBBSAdDC/Pnzo6qqKqqrq2P58uXRu3fvqKysjE2bNrU6/5VXXolhw4bF1VdfHa+//noMGTIkhgwZEn/84x9zXDkAALC/ykuSJEm7CAD2LQMGDIizzjor7r///oiIaG5ujrKysrjxxhtj3LhxLeYPHTo0Ghsb47nnnsuMnXPOOdGnT5+YPXv2556voaEhSkpKor6+PoqLi9vuQgAOUu6rLekJQNtqj/uqlVQAZNm5c2csW7YsKioqMmP5+flRUVERS5cubfWYpUuXZs2PiKisrNzlfAAAgE/rkHYBAOxbtmzZEk1NTVFaWpo1XlpaGqtWrWr1mNra2lbn19bWtjp/x44dsWPHjszX9fX1EfG3v8YA8MV9cj/10AQA+xMhFQA5V1NTE1OmTGkxXlZWlkI1AAeu9957L0pKStIuAwB2i5AKgCxdunSJgoKCqKuryxqvq6uLbt26tXpMt27d9mj++PHjo6qqKvP11q1b47jjjov169f7Zer/19DQEGVlZbFhwwZ7p4R+fJp+tKQn2err6+PYY4+NI488Mu1SAGC3CakAyNKxY8fo169fLF68OIYMGRIRf9s4ffHixTF69OhWjykvL4/FixfHzTffnBl74YUXory8vNX5hYWFUVhY2GK8pKTEL5efUlxcrCd/Rz+y6UdLepItP98WtADsP4RUALRQVVUVI0eOjP79+8fZZ58dM2fOjMbGxhg1alRERIwYMSJ69OgRNTU1ERFx0003xde//vWYMWNGXHzxxTFv3rx47bXX4sEHH0zzMgAAgP2IkAqAFoYOHRqbN2+OyZMnR21tbfTp0ycWLVqU2Rx9/fr1WX+dHzhwYDz22GMxceLEmDBhQpx88snxzDPPxOmnn57WJQAAAPsZIRUArRo9evQuH+9bsmRJi7Fvfetb8a1vfWuvzlVYWBjV1dWtPgJ4sNKTbPqRTT9a0pNs+gHA/igv8bm0AADAAa6hoSFKSkqivr7evmUAbaA97qt2UgQAAAAgdUIqAAAAAFInpAIAAAAgdUIqAAAAAFInpAIgJ2bNmhU9e/aMoqKiGDBgQLz66qufOf+JJ56IU089NYqKiqJXr16xcOHCHFWaO3vSkzlz5sT5558fnTt3js6dO0dFRcXn9nB/s6c/I5+YN29e5OXlxZAhQ9q3wBzb035s3bo1brjhhujevXsUFhbGV77ylQPu/5s97cnMmTPjlFNOiU6dOkVZWVmMGTMmPvzwwxxV275eeumlGDx4cBxzzDGRl5cXzzzzzOces2TJkjjzzDOjsLAwTjrppJg7d2671wkAe0JIBUC7mz9/flRVVUV1dXUsX748evfuHZWVlbFp06ZW57/yyisxbNiwuPrqq+P111+PIUOGxJAhQ+KPf/xjjitvP3vakyVLlsSwYcPixRdfjKVLl0ZZWVlceOGFsXHjxhxX3j72tB+fWLduXdxyyy1x/vnn56jS3NjTfuzcuTMuuOCCWLduXTz55JPx5ptvxpw5c6JHjx45rrz97GlPHnvssRg3blxUV1fHypUr4+GHH4758+fHhAkTclx5+2hsbIzevXvHrFmzdmv+2rVr4+KLL45BgwbFihUr4uabb45rrrkmnn/++XauFAB2X16SJEnaRQBwYBswYECcddZZcf/990dERHNzc5SVlcWNN94Y48aNazF/6NCh0djYGM8991xm7Jxzzok+ffrE7Nmzc1Z3e9rTnnxaU1NTdO7cOe6///4YMWJEe5fb7vamH01NTfG1r30tvvvd78Zvf/vb2Lp1626tJtkf7Gk/Zs+eHffcc0+sWrUqDjnkkFyXmxN72pPRo0fHypUrY/HixZmxH/zgB/G73/0uXn755ZzVnQt5eXnx9NNPf+ZqwrFjx8aCBQuywv7vfOc7sXXr1li0aFEOqkxfe3xUOsDBrD3uq1ZSAdCudu7cGcuWLYuKiorMWH5+flRUVMTSpUtbPWbp0qVZ8yMiKisrdzl/f7M3Pfm07du3x0cffRRHHnlke5WZM3vbjzvuuCO6du0aV199dS7KzJm96cezzz4b5eXlccMNN0RpaWmcfvrpMW3atGhqaspV2e1qb3oycODAWLZsWeaRwDVr1sTChQvjoosuyknN+5oD/b4KwIGhQ9oFAHBg27JlSzQ1NUVpaWnWeGlpaaxatarVY2pra1udX1tb22515tLe9OTTxo4dG8ccc0yLXzr3R3vTj5dffjkefvjhWLFiRQ4qzK296ceaNWviN7/5TVx55ZWxcOHCWL16dXz/+9+Pjz76KKqrq3NRdrvam55cccUVsWXLljjvvPMiSZL4+OOP4/rrrz9gHvfbU7u6rzY0NMQHH3wQnTp1SqkyAPhPVlIBwH5m+vTpMW/evHj66aejqKgo7XJybtu2bTF8+PCYM2dOdOnSJe1y9gnNzc3RtWvXePDBB6Nfv34xdOjQuO222w6Yx2P3xpIlS2LatGnxwAMPxPLly+Opp56KBQsWxNSpU9MuDQDYBSEVAO2qS5cuUVBQEHV1dVnjdXV10a1bt1aP6dat2x7N39/sTU8+ce+998b06dPjV7/6VZxxxhntWWbO7Gk/3n777Vi3bl0MHjw4OnToEB06dIhf/OIX8eyzz0aHDh3i7bffzlXp7WJvfj66d+8eX/nKV6KgoCAz9tWvfjVqa2tj586d7VpvLuxNTyZNmhTDhw+Pa665Jnr16hWXXXZZTJs2LWpqaqK5uTkXZe9TdnVfLS4uTm0VlU99BeDThFQAtKuOHTtGv379sjYvbm5ujsWLF0d5eXmrx5SXl2fNj4h44YUXdjl/f7M3PYmIuPvuu2Pq1KmxaNGi6N+/fy5KzYk97cepp54ab7zxRqxYsSLzuvTSSzOfWlZWVpbL8tvc3vx8nHvuubF69eqs8OWtt96K7t27R8eOHdu95va2Nz3Zvn175Odn/1P3kxDvYPzcoH3tvupTXwFoVQIA7WzevHlJYWFhMnfu3OTPf/5zct111yVHHHFEUltbmyRJkgwfPjwZN25cZv6///u/Jx06dEjuvffeZOXKlUl1dXVyyCGHJG+88UZal9Dm9rQn06dPTzp27Jg8+eSTybvvvpt5bdu2La1LaFN72o9PGzlyZPLNb34zR9W2vz3tx/r165PDDz88GT16dPLmm28mzz33XNK1a9fkRz/6UVqX0Ob2tCfV1dXJ4Ycfnjz++OPJmjVrkl/96lfJiSeemHz7299O6xLa1LZt25LXX389ef3115OISO67777k9ddfT955550kSZJk3LhxyfDhwzPz16xZkxx66KHJrbfemqxcuTKZNWtWUlBQkCxatCiV+s8+++zkhhtuyHzd1NSUHHPMMUlNTU2r87/97W8nF198cdbYgAEDku9973u7fc76+vokIpL6+vq9KxqALO1xX7VxOgDtbujQobF58+aYPHly1NbWRp8+fWLRokWZTXzXr1+fteJh4MCB8dhjj8XEiRNjwoQJcfLJJ8czzzwTp59+elqX0Ob2tCc//elPY+fOnXH55ZdnvU91dXXcfvvtuSy9XexpPw50e9qPsrKyeP7552PMmDFxxhlnRI8ePeKmm26KsWPHpnUJbW5PezJx4sTIy8uLiRMnxsaNG+Poo4+OwYMHx5133pnWJbSp1157LQYNGpT5uqqqKiIiRo4cGXPnzo1333031q9fn/n+8ccfHwsWLIgxY8bEj3/84/jyl78cDz30UFRWVua89k8+rXH8+PGZsd351NdPrvETlZWV8cwzz+zyPDt27IgdO3Zkvq6vr4+Iv31kOgBf3Cf306QNVyjnJW35bgAAAJ/hP/7jP6JHjx7xyiuvZD1u+MMf/jD+7d/+LX73u9+1OKZjx47x6KOPxrBhwzJjDzzwQEyZMqXFXlufuP3222PKlCltfwEAZHn77bfjhBNOaJP3spIKAAA44IwfPz5r9dXWrVvjuOOOi/Xr10dJSUmKle0bGhoaoqysLDZs2BDFxcVpl5M6/WhJT7LpR0v19fVx7LHHxpFHHtlm7ymkAgAAciZXn/paWFgYhYWFLcZLSkr8gvl3iouL9ePv6EdLepJNP1pqyy0ZDp7NHQAAgNT51FcAdsVKKgAAIKeqqqpi5MiR0b9//zj77LNj5syZ0djYGKNGjYqIiBEjRkSPHj2ipqYmIiJuuumm+PrXvx4zZsyIiy++OObNmxevvfZaPPjgg2leBgBtTEgFAADkVBqf+lpYWBjV1dWtPgJ4MNKPbPrRkp5k04+W2qMnPt0PAAAAgNTZkwoAAACA1AmpAAAAAEidkAoAAACA1AmpAAAAAEidkAoAADggzJo1K3r27BlFRUUxYMCAePXVVz9z/hNPPBGnnnpqFBUVRa9evWLhwoU5qjQ39qQfc+bMifPPPz86d+4cnTt3joqKis/t3/5mT38+PjFv3rzIy8uLIUOGtG+BKdjTnmzdujVuuOGG6N69exQWFsZXvvKVA+r/mz3tx8yZM+OUU06JTp06RVlZWYwZMyY+/PDDHFXbvl566aUYPHhwHHPMMZGXlxfPPPPM5x6zZMmSOPPMM6OwsDBOOumkmDt37h6fV0gFAADs9+bPnx9VVVVRXV0dy5cvj969e0dlZWVs2rSp1fmvvPJKDBs2LK6++up4/fXXY8iQITFkyJD44x//mOPK28ee9mPJkiUxbNiwePHFF2Pp0qVRVlYWF154YWzcuDHHlbePPe3HJ9atWxe33HJLnH/++TmqNHf2tCc7d+6MCy64INatWxdPPvlkvPnmmzFnzpzo0aNHjitvH3vaj8ceeyzGjRsX1dXVsXLlynj44Ydj/vz5MWHChBxX3j4aGxujd+/eMWvWrN2av3bt2rj44otj0KBBsWLFirj55pvjmmuuieeff36PzpuXJEmyNwUDAADsKwYMGBBnnXVW3H///RER0dzcHGVlZXHjjTfGuHHjWswfOnRoNDY2xnPPPZcZO+ecc6JPnz4xe/bsnNXdXva0H5/W1NQUnTt3jvvvvz9GjBjR3uW2u73pR1NTU3zta1+L7373u/Hb3/42tm7dulurSfYXe9qT2bNnxz333BOrVq2KQw45JNfltrs97cfo0aNj5cqVsXjx4szYD37wg/jd734XL7/8cs7qzoW8vLx4+umnP3M14dixY2PBggVZQf93vvOd2Lp1ayxatGi3z2UlFQAAsF/buXNnLFu2LCoqKjJj+fn5UVFREUuXLm31mKVLl2bNj4iorKzc5fz9yd7049O2b98eH330URx55JHtVWbO7G0/7rjjjujatWtcffXVuSgzp/amJ88++2yUl5fHDTfcEKWlpXH66afHtGnToqmpKVdlt5u96cfAgQNj2bJlmUcC16xZEwsXLoyLLrooJzXva9rqntqhLYsCAADItS1btkRTU1OUlpZmjZeWlsaqVataPaa2trbV+bW1te1WZ67sTT8+bezYsXHMMce0+KVzf7Q3/Xj55Zfj4YcfjhUrVuSgwtzbm56sWbMmfvOb38SVV14ZCxcujNWrV8f3v//9+Oijj6K6ujoXZbebvenHFVdcEVu2bInzzjsvkiSJjz/+OK6//voD5nG/PbWre2pDQ0N88MEH0alTp916HyupAAAAyJg+fXrMmzcvnn766SgqKkq7nJzbtm1bDB8+PObMmRNdunRJu5x9RnNzc3Tt2jUefPDB6NevXwwdOjRuu+22A+Lx2L2xZMmSmDZtWjzwwAOxfPnyeOqpp2LBggUxderUtEvbr1lJBQAA7Ne6dOkSBQUFUVdXlzVeV1cX3bp1a/WYbt267dH8/cne9OMT9957b0yfPj1+/etfxxlnnNGeZebMnvbj7bffjnXr1sXgwYMzY83NzRER0aFDh3jzzTfjxBNPbN+i29ne/Ix07949DjnkkCgoKMiMffWrX43a2trYuXNndOzYsV1rbk97049JkybF8OHD45prromIiF69ekVjY2Ncd911cdttt0V+/sG1JmhX99Ti4uLdXkUVYSUVAACwn+vYsWP069cvawPj5ubmWLx4cZSXl7d6THl5edb8iIgXXnhhl/P3J3vTj4iIu+++O6ZOnRqLFi2K/v3756LUnNjTfpx66qnxxhtvxIoVKzKvSy+9NPOpZWVlZbksv13szc/IueeeG6tXr84EdhERb731VnTv3n2/Dqgi9q4f27dvbxFEfRLgHYyfT9dm99QEAABgPzdv3ryksLAwmTt3bvLnP/85ue6665Ijjjgiqa2tTZIkSYYPH56MGzcuM//f//3fkw4dOiT33ntvsnLlyqS6ujo55JBDkjfeeCOtS2hTe9qP6dOnJx07dkyefPLJ5N133828tm3bltYltKk97cenjRw5MvnmN7+Zo2pzY097sn79+uTwww9PRo8enbz55pvJc889l3Tt2jX50Y9+lNYltKk97Ud1dXVy+OGHJ48//niyZs2a5Fe/+lVy4oknJt/+9rfTuoQ2tW3btuT1119PXn/99SQikvvuuy95/fXXk3feeSdJkiQZN25cMnz48Mz8NWvWJIceemhy6623JitXrkxmzZqVFBQUJIsWLdqj83rcDwAA2O8NHTo0Nm/eHJMnT47a2tro06dPLFq0KLOR7/r167NWPQwcODAee+yxmDhxYkyYMCFOPvnkeOaZZ+L0009P6xLa1J7246c//Wns3LkzLr/88qz3qa6ujttvvz2XpbeLPe3HwWBPe1JWVhbPP/98jBkzJs4444zo0aNH3HTTTTF27Ni0LqFN7Wk/Jk6cGHl5eTFx4sTYuHFjHH300TF48OC4884707qENvXaa6/FoEGDMl9XVVVFRMTIkSNj7ty58e6778b69esz3z/++ONjwYIFMWbMmPjxj38cX/7yl+Ohhx6KysrKPTpvXpIchOvQAAAAANinHFxRMQAAAAD7JCEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKkTUgEAAACQOiEVAAAAAKn7/wC49OhWpd0SZQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executing and table creating"
      ],
      "metadata": {
        "id": "4HB1xk9AWtwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Assuming `test_dataloader` is your DataLoader with test data\n",
        "# and `model` is your trained PyTorch model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "mean_metrics = test_model_and_calculate_statistics(model, dataloader, device=device)\n",
        "\n",
        "# Print the results\n",
        "print(\"Mean Metrics:\", mean_metrics)\n",
        "#print(\"P-Value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSqTODghiab3",
        "outputId": "9fa45b5e-d88c-4462-af3e-d410e0a0c3c8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Metrics: {'accuracy': 0.9984032415574596, 'precision': 0.9985151646375878, 'recall': 0.9998874818424989, 'f1': 0.9991953598640486, 'iou': 0.9984031274194538}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate  # Optional, for a nice CLI table\n",
        "\n",
        "def print_metrics_table(metrics_dict):\n",
        "    \"\"\"\n",
        "    Print metrics in a tabular format using pandas DataFrame.\n",
        "    \"\"\"\n",
        "    # Create a DataFrame from the metrics dictionary\n",
        "    metrics_df = pd.DataFrame([metrics_dict])\n",
        "\n",
        "    # Print as a table\n",
        "    print(\"Metrics Table:\")\n",
        "    print(tabulate(metrics_df, headers=\"keys\", tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "# Example Usage in Model Testing\n",
        "mean_metrics = {\n",
        "    \"Accuracy\": 0.9984041124064632,\n",
        "    \"Precision\": 0.9985147215265792,\n",
        "    \"Recall\": 0.9998888119327677,\n",
        "    \"F1-Score\": 0.9991957977679148,\n",
        "    \"IoU\": 0.9984040054103518\n",
        "}\n",
        "\n",
        "# Call the function to display metrics\n",
        "print_metrics_table(mean_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQOYXH7TBQDa",
        "outputId": "bf173120-4276-4f5a-fc29-aaed89b2023f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "+----+------------+-------------+----------+------------+----------+\n",
            "|    |   Accuracy |   Precision |   Recall |   F1-Score |      IoU |\n",
            "+====+============+=============+==========+============+==========+\n",
            "|  0 |   0.998404 |    0.998515 | 0.999889 |   0.999196 | 0.998404 |\n",
            "+----+------------+-------------+----------+------------+----------+\n"
          ]
        }
      ]
    }
  ]
}